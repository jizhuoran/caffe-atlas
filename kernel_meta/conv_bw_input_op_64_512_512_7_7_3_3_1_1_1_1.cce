#ifdef __CCE_KT_TEST__
#define __aicore__ 
#else
#define __aicore__ [aicore]
#endif

extern "C"  __global__ __aicore__ void conv_bw_input_op_64_512_512_7_7_3_3_1_1_1_1__kernel0(__gm__ half* __restrict__ filter, __gm__ half* __restrict__ dedy, __gm__ half* __restrict__ c_ddr) {
set_l1_3d_size(0);
set_padding(0);
__cbuf__   half* dedy_local_L1_1 = (__cbuf__  half *)get_imm(0);
__cc__   float* C_2 = (__cc__  float *)get_imm(0);
__cbuf__   half* filter_local_L1_3 = (__cbuf__  half *)get_imm(50176);
__ca__   half* im2col_fractal_4 = (__ca__  half *)get_imm(0);
__cb__   half* w_col_5 = (__cb__  half *)get_imm(0);
__ca__   half* im2col_fractal_6 = (__ca__  half *)get_imm(18432);
__cb__   half* w_col_7 = (__cb__  half *)get_imm(18432);
__cbuf__   half* filter_local_L1_8 = (__cbuf__  half *)get_imm(87040);
__ubuf__   half* c_ub_9 = (__ubuf__  half *)get_imm(0);
__ubuf__   half* c_ub_10 = (__ubuf__  half *)get_imm(4096);
__cbuf__   half* dedy_local_L1_11 = (__cbuf__  half *)get_imm(123904);
__cc__   float* C_12 = (__cc__  float *)get_imm(16384);
  set_padding((uint64_t)0ULL);
  set_fmatrix(0x101010100070007);
  for (int32_t dx_batch_idx_outer_inner = 0; dx_batch_idx_outer_inner < 32; ++dx_batch_idx_outer_inner) {
    for (int32_t dx_cin1_idx_outer_outer_inner_db = 0; dx_cin1_idx_outer_outer_inner_db < 4; ++dx_cin1_idx_outer_outer_inner_db) {
      copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L1_1), ((__gm__ half *)dedy + ((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088))), 0, 1, 1568, 0, 0, PAD_NONE);
      set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
            if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0) {
        wait_flag(PIPE_V, PIPE_M, EVENT_ID0);
      }
      wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
      for (int32_t axis_k1_outer_outer_db = 0; axis_k1_outer_outer_db < 8; ++axis_k1_outer_outer_db) {
        if (((axis_k1_outer_outer_db == 0) && ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0)) || (0 < axis_k1_outer_outer_db)) {
          wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
        }
        copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1_3), ((__gm__ half *)filter + ((dx_cin1_idx_outer_outer_inner_db * 589824) + (axis_k1_outer_outer_db * 1024))), 0, 36, 32, 480, 0, PAD_NONE);
        set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        if (((axis_k1_outer_outer_db == 0) && ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0)) || (0 < axis_k1_outer_outer_db)) {
          wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        }
        for (int32_t lower = 0; lower < 4; ++lower) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)(((((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)18) - ((int64_t)(((uint64_t)(((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)2)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)(((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)2)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        for (int32_t w_k1_idx = 0; w_k1_idx < 9; ++w_k1_idx) {
          load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx * 1024)), ((__cbuf__ half *)filter_local_L1_3 + (4096 - (w_k1_idx * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (axis_k1_outer_outer_db == 0));
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        if (((axis_k1_outer_outer_db == 0) && ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0)) || (0 < axis_k1_outer_outer_db)) {
          wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        }
        for (int32_t lower1 = 0; lower1 < 4; ++lower1) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower1 * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)((((((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)18) + (int64_t)9) - ((int64_t)(((uint64_t)((((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)2) + (int64_t)1)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower1) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower1) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)((((int64_t)(axis_k1_outer_outer_db * 2)) * (int64_t)2) + (int64_t)1)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        for (int32_t w_k1_idx1 = 0; w_k1_idx1 < 9; ++w_k1_idx1) {
          load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx1 * 1024)), ((__cbuf__ half *)filter_local_L1_3 + (4352 - (w_k1_idx1 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        if (((axis_k1_outer_outer_db == 0) && ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0)) || (0 < axis_k1_outer_outer_db)) {
          wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
        }
        copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1_8), ((__gm__ half *)filter + (((dx_cin1_idx_outer_outer_inner_db * 589824) + (axis_k1_outer_outer_db * 1024)) + 512)), 0, 36, 32, 480, 0, PAD_NONE);
        set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        for (int32_t lower2 = 0; lower2 < 4; ++lower2) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower2 * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)(((((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)18) - ((int64_t)(((uint64_t)(((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)2)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower2) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower2) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)(((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)2)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        for (int32_t w_k1_idx2 = 0; w_k1_idx2 < 9; ++w_k1_idx2) {
          load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx2 * 1024)), ((__cbuf__ half *)filter_local_L1_8 + (4096 - (w_k1_idx2 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (int8_t)0ULL);
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        for (int32_t lower3 = 0; lower3 < 4; ++lower3) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower3 * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)((((((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)18) + (int64_t)9) - ((int64_t)(((uint64_t)((((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)2) + (int64_t)1)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower3) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower3) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)((((int64_t)((axis_k1_outer_outer_db * 2) + 1)) * (int64_t)2) + (int64_t)1)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        for (int32_t w_k1_idx3 = 0; w_k1_idx3 < 9; ++w_k1_idx3) {
          load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx3 * 1024)), ((__cbuf__ half *)filter_local_L1_8 + (4352 - (w_k1_idx3 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
      set_flag(PIPE_M, PIPE_V, EVENT_ID0);
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0) {
        wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
      }
      wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
      copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_9), ((__cc__ float *)C_2), 0, 1, 8, 0, 0, CRMODE_F32toF16_NONE);
      set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      for (int32_t dx_cin1_idx_inner = 0; dx_cin1_idx_inner < 2; ++dx_cin1_idx_inner) {
        copy_ubuf_to_gm(((__gm__ half *)c_ddr + ((((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088)) + (dx_cin1_idx_outer_outer_inner_db * 6272)) + (dx_cin1_idx_inner * 784))), ((__ubuf__ half *)c_ub_9 + (dx_cin1_idx_inner * 1024)), 0, 1, 49, 0, 0);
      }
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0) {
        wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
      }
      copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_10), ((__cc__ float *)C_2 + 2048), 0, 1, 8, 0, 0, CRMODE_F32toF16_NONE);
      set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 34) {
        set_flag(PIPE_V, PIPE_M, EVENT_ID0);
      }
      wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      for (int32_t dx_cin1_idx_inner1 = 0; dx_cin1_idx_inner1 < 2; ++dx_cin1_idx_inner1) {
        copy_ubuf_to_gm(((__gm__ half *)c_ddr + (((((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088)) + (dx_cin1_idx_outer_outer_inner_db * 6272)) + (dx_cin1_idx_inner1 * 784)) + 1568)), ((__ubuf__ half *)c_ub_10 + (dx_cin1_idx_inner1 * 1024)), 0, 1, 49, 0, 0);
      }
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
      copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L1_11), ((__gm__ half *)dedy + ((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088))), 0, 1, 1568, 0, 0, PAD_NONE);
      set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
            if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 0) {
        wait_flag(PIPE_V, PIPE_M, EVENT_ID1);
      }
      wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
      for (int32_t axis_k1_outer_outer_db1 = 0; axis_k1_outer_outer_db1 < 8; ++axis_k1_outer_outer_db1) {
        wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
        copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1_3), ((__gm__ half *)filter + (((dx_cin1_idx_outer_outer_inner_db * 589824) + (axis_k1_outer_outer_db1 * 1024)) + 294912)), 0, 36, 32, 480, 0, PAD_NONE);
        set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        for (int32_t lower4 = 0; lower4 < 4; ++lower4) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower4 * 2304)), ((__cbuf__ half *)dedy_local_L1_11), ((uint64_t)(((((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)18) - ((int64_t)(((uint64_t)(((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)2)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower4) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower4) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)(((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)2)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        for (int32_t w_k1_idx4 = 0; w_k1_idx4 < 9; ++w_k1_idx4) {
          load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx4 * 1024)), ((__cbuf__ half *)filter_local_L1_3 + (4096 - (w_k1_idx4 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_12), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (axis_k1_outer_outer_db1 == 0));
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        for (int32_t lower5 = 0; lower5 < 4; ++lower5) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower5 * 2304)), ((__cbuf__ half *)dedy_local_L1_11), ((uint64_t)((((((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)18) + (int64_t)9) - ((int64_t)(((uint64_t)((((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)2) + (int64_t)1)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower5) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower5) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)((((int64_t)(axis_k1_outer_outer_db1 * 2)) * (int64_t)2) + (int64_t)1)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        for (int32_t w_k1_idx5 = 0; w_k1_idx5 < 9; ++w_k1_idx5) {
          load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx5 * 1024)), ((__cbuf__ half *)filter_local_L1_3 + (4352 - (w_k1_idx5 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        if ((((dx_cin1_idx_outer_outer_inner_db == 3) && ((axis_k1_outer_outer_db1 == 7) && (dx_batch_idx_outer_inner < 31))) || ((axis_k1_outer_outer_db1 == 7) && (dx_cin1_idx_outer_outer_inner_db < 3))) || (axis_k1_outer_outer_db1 < 7)) {
          set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
        }
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_12), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
        copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1_8), ((__gm__ half *)filter + (((dx_cin1_idx_outer_outer_inner_db * 589824) + (axis_k1_outer_outer_db1 * 1024)) + 295424)), 0, 36, 32, 480, 0, PAD_NONE);
        set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        for (int32_t lower6 = 0; lower6 < 4; ++lower6) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower6 * 2304)), ((__cbuf__ half *)dedy_local_L1_11), ((uint64_t)(((((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)18) - ((int64_t)(((uint64_t)(((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)2)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower6) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower6) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)(((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)2)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        for (int32_t w_k1_idx6 = 0; w_k1_idx6 < 9; ++w_k1_idx6) {
          load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx6 * 1024)), ((__cbuf__ half *)filter_local_L1_8 + (4096 - (w_k1_idx6 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_12), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (int8_t)0ULL);
        if ((((dx_cin1_idx_outer_outer_inner_db == 3) && ((axis_k1_outer_outer_db1 == 7) && (dx_batch_idx_outer_inner < 31))) || ((axis_k1_outer_outer_db1 == 7) && (dx_cin1_idx_outer_outer_inner_db < 3))) || (axis_k1_outer_outer_db1 < 7)) {
          set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
        }
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        for (int32_t lower7 = 0; lower7 < 4; ++lower7) {
          img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower7 * 2304)), ((__cbuf__ half *)dedy_local_L1_11), ((uint64_t)((((((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)18) + (int64_t)9) - ((int64_t)(((uint64_t)((((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)2) + (int64_t)1)) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (((((int64_t)lower7) * (int64_t)16) % (int64_t)7) - (int64_t)1), (((((int64_t)lower7) * (int64_t)16) / (int64_t)7) - (int64_t)1), ((uint64_t)((((int64_t)((axis_k1_outer_outer_db1 * 2) + 1)) * (int64_t)2) + (int64_t)1)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
        }
        for (int32_t w_k1_idx7 = 0; w_k1_idx7 < 9; ++w_k1_idx7) {
          load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx7 * 1024)), ((__cbuf__ half *)filter_local_L1_8 + (4352 - (w_k1_idx7 * 512))), 0, 4, 18, 0, 1);
        }
        set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        if ((((dx_cin1_idx_outer_outer_inner_db == 3) && ((axis_k1_outer_outer_db1 == 7) && (dx_batch_idx_outer_inner < 31))) || ((axis_k1_outer_outer_db1 == 7) && (dx_cin1_idx_outer_outer_inner_db < 3))) || (axis_k1_outer_outer_db1 < 7)) {
          set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
        }
        wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
        mad(((__cc__ float *)C_12), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
        if ((((dx_cin1_idx_outer_outer_inner_db == 3) && ((axis_k1_outer_outer_db1 == 7) && (dx_batch_idx_outer_inner < 31))) || ((axis_k1_outer_outer_db1 == 7) && (dx_cin1_idx_outer_outer_inner_db < 3))) || (axis_k1_outer_outer_db1 < 7)) {
          set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
        }
      }
      set_flag(PIPE_M, PIPE_V, EVENT_ID0);
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
      wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
      copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_9), ((__cc__ float *)C_12), 0, 1, 8, 0, 0, CRMODE_F32toF16_NONE);
      set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      for (int32_t dx_cin1_idx_inner2 = 0; dx_cin1_idx_inner2 < 2; ++dx_cin1_idx_inner2) {
        copy_ubuf_to_gm(((__gm__ half *)c_ddr + (((((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088)) + (dx_cin1_idx_outer_outer_inner_db * 6272)) + (dx_cin1_idx_inner2 * 784)) + 3136)), ((__ubuf__ half *)c_ub_9 + (dx_cin1_idx_inner2 * 1024)), 0, 1, 49, 0, 0);
      }
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 34) {
        set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
      }
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
      copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_10), ((__cc__ float *)C_12 + 2048), 0, 1, 8, 0, 0, CRMODE_F32toF16_NONE);
      set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 34) {
        set_flag(PIPE_V, PIPE_M, EVENT_ID1);
      }
      wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
      for (int32_t dx_cin1_idx_inner3 = 0; dx_cin1_idx_inner3 < 2; ++dx_cin1_idx_inner3) {
        copy_ubuf_to_gm(((__gm__ half *)c_ddr + (((((((int32_t)block_idx) * 802816) + (dx_batch_idx_outer_inner * 25088)) + (dx_cin1_idx_outer_outer_inner_db * 6272)) + (dx_cin1_idx_inner3 * 784)) + 4704)), ((__ubuf__ half *)c_ub_10 + (dx_cin1_idx_inner3 * 1024)), 0, 1, 49, 0, 0);
      }
      if ((dx_cin1_idx_outer_outer_inner_db + dx_batch_idx_outer_inner) != 34) {
        set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
      }
    }
  }
  pipe_barrier(PIPE_ALL);
}

