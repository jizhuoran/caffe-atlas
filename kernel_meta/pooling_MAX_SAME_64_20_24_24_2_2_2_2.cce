#ifdef __CCE_KT_TEST__
#define __aicore__ 
#else
#define __aicore__ [aicore]
#endif


#define VERIFY_L2Buffer_OK(l2DataIndex) \
	(0x01 & (((0xFF)&(~l2_in_main)) >> (l2DataIndex)))

extern "C"  __global__ __aicore__ void pooling_MAX_SAME_64_20_24_24_2_2_2_2__kernel0(__gm__ half* __restrict__ data, __gm__ half* __restrict__ res,int64_t index0, uint64_t offset0, int64_t index1, uint64_t offset1) {
  if (index0 >= 0) {
    if (VERIFY_L2Buffer_OK(index0)) {
      data = (__gm__ half*)((uint64_t)l2_vaddr_base + offset0);
    }
  }
  if (index1 >= 0) {
    if (VERIFY_L2Buffer_OK(index1)) {
      res = (__gm__ half*)((uint64_t)l2_vaddr_base + offset1);
    }
  }
set_l1_3d_size(0);
set_padding(0);
set_vector_mask((uint64_t)-1, (uint64_t)-1);
__cbuf__   half* input_fmap_l1_2 = (__cbuf__  half *)get_imm(0);
__ubuf__   half* im2col_fractal_1 = (__ubuf__  half *)get_imm(0);
__cbuf__   half* input_fmap_l1_4 = (__cbuf__  half *)get_imm(36864);
__ubuf__   half* im2col_fractal_3 = (__ubuf__  half *)get_imm(36864);
__ubuf__   half* pooling2d_max = (__ubuf__  half *)get_imm(73728);
__ubuf__   half* pooling2d_max1 = (__ubuf__  half *)get_imm(82944);
__ubuf__   half* pooling2d_max2 = (__ubuf__  half *)get_imm(92160);
__ubuf__   half* pooling2d_max3 = (__ubuf__  half *)get_imm(101376);
  set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
  set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
  set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
  set_fmatrix((uint64_t)1572888);
  copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_2 + 0), ((__gm__ half *)data + 0), 0, 1, 1152, 0, 0, PAD_NONE);
  set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  for (int32_t lower = 0; lower < 8; ++lower) {
    pipe_barrier(PIPE_MTE1);
    img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_1 + (lower * 256)), ((__cbuf__ half *)input_fmap_l1_2 + 0), ((uint64_t)((((int64_t)lower) - ((int64_t)(((uint64_t)(((int64_t)lower) / (int64_t)4)) * (uint64_t)4))) % (int64_t)2)), ((uint64_t)((((int64_t)lower) % (int64_t)4) / (int64_t)2)), (int64_t)0, (int64_t)0, ((uint64_t)(((int64_t)lower) / (int64_t)4)), (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)8, (uint64_t)1, (uint64_t)9, (csize_t)0);
  }
  set_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
  set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
  for (int32_t i0_inner_db = 0; i0_inner_db < 31; ++i0_inner_db) {
    wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_4 + 0), ((__gm__ half *)data + ((i0_inner_db * 36864) + 18432)), 0, 1, 1152, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t lower1 = 0; lower1 < 8; ++lower1) {
      pipe_barrier(PIPE_MTE1);
      img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_3 + (lower1 * 256)), ((__cbuf__ half *)input_fmap_l1_4 + 0), ((uint64_t)((((int64_t)lower1) - ((int64_t)(((uint64_t)(((int64_t)lower1) / (int64_t)4)) * (uint64_t)4))) % (int64_t)2)), ((uint64_t)((((int64_t)lower1) % (int64_t)4) / (int64_t)2)), (int64_t)0, (int64_t)0, ((uint64_t)(((int64_t)lower1) / (int64_t)4)), (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)8, (uint64_t)1, (uint64_t)9, (csize_t)0);
    }
    set_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
    set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    vector_dup(((__ubuf__ half *)pooling2d_max + 0), (half)-6.550400e+04f, 36, 1, 1, 8, 8);
    wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
    pipe_barrier(PIPE_V);
    for (int32_t loop_inner_w = 0; loop_inner_w < 4; ++loop_inner_w) {
      pipe_barrier(PIPE_V);
      vmax(((__ubuf__ half *)pooling2d_max + 0), ((__ubuf__ half *)pooling2d_max + 0), ((__ubuf__ half *)im2col_fractal_1 + (loop_inner_w * 256)), 18, 1, 1, 1, 16, 16, 64);
      vmax(((__ubuf__ half *)pooling2d_max + 128), ((__ubuf__ half *)pooling2d_max + 128), ((__ubuf__ half *)im2col_fractal_1 + ((loop_inner_w * 256) + 128)), 18, 1, 1, 1, 16, 16, 64);
    }
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 294912) + (i0_inner_db * 9216))), ((__ubuf__ half *)pooling2d_max + 0), 0, 9, 16, 16, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 294912) + (i0_inner_db * 9216)) + 2304)), ((__ubuf__ half *)pooling2d_max + 256), 0, 9, 16, 16, 0);
    set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_2 + 0), ((__gm__ half *)data + ((i0_inner_db * 36864) + 36864)), 0, 1, 1152, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t lower2 = 0; lower2 < 8; ++lower2) {
      pipe_barrier(PIPE_MTE1);
      img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_1 + (lower2 * 256)), ((__cbuf__ half *)input_fmap_l1_2 + 0), ((uint64_t)((((int64_t)lower2) - ((int64_t)(((uint64_t)(((int64_t)lower2) / (int64_t)4)) * (uint64_t)4))) % (int64_t)2)), ((uint64_t)((((int64_t)lower2) % (int64_t)4) / (int64_t)2)), (int64_t)0, (int64_t)0, ((uint64_t)(((int64_t)lower2) / (int64_t)4)), (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)8, (uint64_t)1, (uint64_t)9, (csize_t)0);
    }
    set_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
    set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    vector_dup(((__ubuf__ half *)pooling2d_max1 + 0), (half)-6.550400e+04f, 36, 1, 1, 8, 8);
    wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
    pipe_barrier(PIPE_V);
    for (int32_t loop_inner_w1 = 0; loop_inner_w1 < 4; ++loop_inner_w1) {
      pipe_barrier(PIPE_V);
      vmax(((__ubuf__ half *)pooling2d_max1 + 0), ((__ubuf__ half *)pooling2d_max1 + 0), ((__ubuf__ half *)im2col_fractal_3 + (loop_inner_w1 * 256)), 18, 1, 1, 1, 16, 16, 64);
      vmax(((__ubuf__ half *)pooling2d_max1 + 128), ((__ubuf__ half *)pooling2d_max1 + 128), ((__ubuf__ half *)im2col_fractal_3 + ((loop_inner_w1 * 256) + 128)), 18, 1, 1, 1, 16, 16, 64);
    }
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 294912) + (i0_inner_db * 9216)) + 4608)), ((__ubuf__ half *)pooling2d_max1 + 0), 0, 9, 16, 16, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 294912) + (i0_inner_db * 9216)) + 6912)), ((__ubuf__ half *)pooling2d_max1 + 256), 0, 9, 16, 16, 0);
    set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  }
  set_flag(PIPE_V, PIPE_MTE1, EVENT_ID1);
      vector_dup(((__ubuf__ half *)pooling2d_max2 + 0), (half)-6.550400e+04f, 36, 1, 1, 8, 8);
  pipe_barrier(PIPE_V);
  wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
  for (int32_t loop_inner_w2 = 0; loop_inner_w2 < 4; ++loop_inner_w2) {
    pipe_barrier(PIPE_V);
    vmax(((__ubuf__ half *)pooling2d_max2 + 0), ((__ubuf__ half *)pooling2d_max2 + 0), ((__ubuf__ half *)im2col_fractal_1 + (loop_inner_w2 * 256)), 18, 1, 1, 1, 16, 16, 64);
    vmax(((__ubuf__ half *)pooling2d_max2 + 128), ((__ubuf__ half *)pooling2d_max2 + 128), ((__ubuf__ half *)im2col_fractal_1 + ((loop_inner_w2 * 256) + 128)), 18, 1, 1, 1, 16, 16, 64);
  }
  set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 294912) + 285696)), ((__ubuf__ half *)pooling2d_max2 + 0), 0, 9, 16, 16, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 294912) + 288000)), ((__ubuf__ half *)pooling2d_max2 + 256), 0, 9, 16, 16, 0);
  wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
  wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
  copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_4 + 0), ((__gm__ half *)data + 1161216), 0, 1, 1152, 0, 0, PAD_NONE);
  set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID1);
  wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
  for (int32_t lower3 = 0; lower3 < 8; ++lower3) {
    pipe_barrier(PIPE_MTE1);
    img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_3 + (lower3 * 256)), ((__cbuf__ half *)input_fmap_l1_4 + 0), ((uint64_t)((((int64_t)lower3) - ((int64_t)(((uint64_t)(((int64_t)lower3) / (int64_t)4)) * (uint64_t)4))) % (int64_t)2)), ((uint64_t)((((int64_t)lower3) % (int64_t)4) / (int64_t)2)), (int64_t)0, (int64_t)0, ((uint64_t)(((int64_t)lower3) / (int64_t)4)), (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)8, (uint64_t)1, (uint64_t)9, (csize_t)0);
  }
  set_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
      vector_dup(((__ubuf__ half *)pooling2d_max3 + 0), (half)-6.550400e+04f, 36, 1, 1, 8, 8);
  wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
  pipe_barrier(PIPE_V);
  for (int32_t loop_inner_w3 = 0; loop_inner_w3 < 4; ++loop_inner_w3) {
    pipe_barrier(PIPE_V);
    vmax(((__ubuf__ half *)pooling2d_max3 + 0), ((__ubuf__ half *)pooling2d_max3 + 0), ((__ubuf__ half *)im2col_fractal_3 + (loop_inner_w3 * 256)), 18, 1, 1, 1, 16, 16, 64);
    vmax(((__ubuf__ half *)pooling2d_max3 + 128), ((__ubuf__ half *)pooling2d_max3 + 128), ((__ubuf__ half *)im2col_fractal_3 + ((loop_inner_w3 * 256) + 128)), 18, 1, 1, 1, 16, 16, 64);
  }
  set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 294912) + 290304)), ((__ubuf__ half *)pooling2d_max3 + 0), 0, 9, 16, 16, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 294912) + 292608)), ((__ubuf__ half *)pooling2d_max3 + 256), 0, 9, 16, 16, 0);
  wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
  wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  pipe_barrier(PIPE_ALL);
}

