#ifdef __CCE_KT_TEST__
#define __aicore__ 
#else
#define __aicore__ [aicore]
#endif


#define VERIFY_L2Buffer_OK(l2DataIndex) \
	(0x01 & (((0xFF)&(~l2_in_main)) >> (l2DataIndex)))

extern "C"  __global__ __aicore__ void pooling_MAX_SAME_64_50_8_8_2_2_2_2__kernel0(__gm__ half* __restrict__ data, __gm__ half* __restrict__ res,int64_t index0, uint64_t offset0, int64_t index1, uint64_t offset1) {
  if (index0 >= 0) {
    if (VERIFY_L2Buffer_OK(index0)) {
      data = (__gm__ half*)((uint64_t)l2_vaddr_base + offset0);
    }
  }
  if (index1 >= 0) {
    if (VERIFY_L2Buffer_OK(index1)) {
      res = (__gm__ half*)((uint64_t)l2_vaddr_base + offset1);
    }
  }
set_l1_3d_size(0);
set_padding(0);
set_vector_mask((uint64_t)-1, (uint64_t)-1);
__cbuf__   half* input_fmap_l1_2 = (__cbuf__  half *)get_imm(0);
__ubuf__   half* im2col_fractal_1 = (__ubuf__  half *)get_imm(0);
__cbuf__   half* input_fmap_l1_4 = (__cbuf__  half *)get_imm(8192);
__ubuf__   half* im2col_fractal_3 = (__ubuf__  half *)get_imm(8192);
__ubuf__   half* pooling2d_max = (__ubuf__  half *)get_imm(16384);
__ubuf__   half* pooling2d_max1 = (__ubuf__  half *)get_imm(18432);
__ubuf__   half* pooling2d_max2 = (__ubuf__  half *)get_imm(20480);
__ubuf__   half* pooling2d_max3 = (__ubuf__  half *)get_imm(22528);
  set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
  set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
  set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
  set_fmatrix((uint64_t)524296);
  copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_2 + 0), ((__gm__ half *)data + 0), 0, 1, 256, 0, 0, PAD_NONE);
  set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_1 + 0), ((__cbuf__ half *)input_fmap_l1_2 + 0), (uint64_t)0, (uint64_t)0, (int64_t)0, (int64_t)0, (uint64_t)0, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)1, (uint64_t)0, (uint64_t)16, (csize_t)0);
  set_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
  set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
  for (int32_t i0_inner_db = 0; i0_inner_db < 31; ++i0_inner_db) {
    wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_4 + 0), ((__gm__ half *)data + ((i0_inner_db * 8192) + 4096)), 0, 1, 256, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_3 + 0), ((__cbuf__ half *)input_fmap_l1_4 + 0), (uint64_t)0, (uint64_t)0, (int64_t)0, (int64_t)0, (uint64_t)0, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)1, (uint64_t)0, (uint64_t)16, (csize_t)0);
    set_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
    set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    vector_dup(((__ubuf__ half *)pooling2d_max + 0), (half)-6.550400e+04f, 8, 1, 1, 8, 8);
    wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
    pipe_barrier(PIPE_V);
    for (int32_t loop_inner_w = 0; loop_inner_w < 4; ++loop_inner_w) {
      pipe_barrier(PIPE_V);
      vmax(((__ubuf__ half *)pooling2d_max + 0), ((__ubuf__ half *)pooling2d_max + 0), ((__ubuf__ half *)im2col_fractal_1 + (loop_inner_w * 256)), 4, 1, 1, 1, 16, 16, 64);
      vmax(((__ubuf__ half *)pooling2d_max + 128), ((__ubuf__ half *)pooling2d_max + 128), ((__ubuf__ half *)im2col_fractal_1 + ((loop_inner_w * 256) + 128)), 4, 1, 1, 1, 16, 16, 64);
    }
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048))), ((__ubuf__ half *)pooling2d_max + 0), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 256)), ((__ubuf__ half *)pooling2d_max + 256), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 512)), ((__ubuf__ half *)pooling2d_max + 512), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 768)), ((__ubuf__ half *)pooling2d_max + 768), 0, 1, 16, 48, 0);
    set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_2 + 0), ((__gm__ half *)data + ((i0_inner_db * 8192) + 8192)), 0, 1, 256, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_1 + 0), ((__cbuf__ half *)input_fmap_l1_2 + 0), (uint64_t)0, (uint64_t)0, (int64_t)0, (int64_t)0, (uint64_t)0, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)1, (uint64_t)0, (uint64_t)16, (csize_t)0);
    set_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
    set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    vector_dup(((__ubuf__ half *)pooling2d_max1 + 0), (half)-6.550400e+04f, 8, 1, 1, 8, 8);
    wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
    pipe_barrier(PIPE_V);
    for (int32_t loop_inner_w1 = 0; loop_inner_w1 < 4; ++loop_inner_w1) {
      pipe_barrier(PIPE_V);
      vmax(((__ubuf__ half *)pooling2d_max1 + 0), ((__ubuf__ half *)pooling2d_max1 + 0), ((__ubuf__ half *)im2col_fractal_3 + (loop_inner_w1 * 256)), 4, 1, 1, 1, 16, 16, 64);
      vmax(((__ubuf__ half *)pooling2d_max1 + 128), ((__ubuf__ half *)pooling2d_max1 + 128), ((__ubuf__ half *)im2col_fractal_3 + ((loop_inner_w1 * 256) + 128)), 4, 1, 1, 1, 16, 16, 64);
    }
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    set_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 1024)), ((__ubuf__ half *)pooling2d_max1 + 0), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 1280)), ((__ubuf__ half *)pooling2d_max1 + 256), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 1536)), ((__ubuf__ half *)pooling2d_max1 + 512), 0, 1, 16, 48, 0);
    copy_ubuf_to_gm(((__gm__ half *)res + (((((int32_t)block_idx) * 65536) + (i0_inner_db * 2048)) + 1792)), ((__ubuf__ half *)pooling2d_max1 + 768), 0, 1, 16, 48, 0);
    set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  }
  set_flag(PIPE_V, PIPE_MTE1, EVENT_ID1);
      vector_dup(((__ubuf__ half *)pooling2d_max2 + 0), (half)-6.550400e+04f, 8, 1, 1, 8, 8);
  pipe_barrier(PIPE_V);
  wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID1);
  for (int32_t loop_inner_w2 = 0; loop_inner_w2 < 4; ++loop_inner_w2) {
    pipe_barrier(PIPE_V);
    vmax(((__ubuf__ half *)pooling2d_max2 + 0), ((__ubuf__ half *)pooling2d_max2 + 0), ((__ubuf__ half *)im2col_fractal_1 + (loop_inner_w2 * 256)), 4, 1, 1, 1, 16, 16, 64);
    vmax(((__ubuf__ half *)pooling2d_max2 + 128), ((__ubuf__ half *)pooling2d_max2 + 128), ((__ubuf__ half *)im2col_fractal_1 + ((loop_inner_w2 * 256) + 128)), 4, 1, 1, 1, 16, 16, 64);
  }
  set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 63488)), ((__ubuf__ half *)pooling2d_max2 + 0), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 63744)), ((__ubuf__ half *)pooling2d_max2 + 256), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 64000)), ((__ubuf__ half *)pooling2d_max2 + 512), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 64256)), ((__ubuf__ half *)pooling2d_max2 + 768), 0, 1, 16, 48, 0);
  wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
  wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
  copy_gm_to_cbuf(((__cbuf__ half *)input_fmap_l1_4 + 0), ((__gm__ half *)data + 258048), 0, 1, 256, 0, 0, PAD_NONE);
  set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID1);
  wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE1, EVENT_ID0);
  img2col_cbuf_to_ub(((__ubuf__ half *)im2col_fractal_3 + 0), ((__cbuf__ half *)input_fmap_l1_4 + 0), (uint64_t)0, (uint64_t)0, (int64_t)0, (int64_t)0, (uint64_t)0, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)2, (uint64_t)1, (uint64_t)1, (uint64_t)1, (uint64_t)0, (uint64_t)16, (csize_t)0);
  set_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
      vector_dup(((__ubuf__ half *)pooling2d_max3 + 0), (half)-6.550400e+04f, 8, 1, 1, 8, 8);
  wait_flag(PIPE_MTE1, PIPE_V, EVENT_ID0);
  pipe_barrier(PIPE_V);
  for (int32_t loop_inner_w3 = 0; loop_inner_w3 < 4; ++loop_inner_w3) {
    pipe_barrier(PIPE_V);
    vmax(((__ubuf__ half *)pooling2d_max3 + 0), ((__ubuf__ half *)pooling2d_max3 + 0), ((__ubuf__ half *)im2col_fractal_3 + (loop_inner_w3 * 256)), 4, 1, 1, 1, 16, 16, 64);
    vmax(((__ubuf__ half *)pooling2d_max3 + 128), ((__ubuf__ half *)pooling2d_max3 + 128), ((__ubuf__ half *)im2col_fractal_3 + ((loop_inner_w3 * 256) + 128)), 4, 1, 1, 1, 16, 16, 64);
  }
  set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 64512)), ((__ubuf__ half *)pooling2d_max3 + 0), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 64768)), ((__ubuf__ half *)pooling2d_max3 + 256), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 65024)), ((__ubuf__ half *)pooling2d_max3 + 512), 0, 1, 16, 48, 0);
  copy_ubuf_to_gm(((__gm__ half *)res + ((((int32_t)block_idx) * 65536) + 65280)), ((__ubuf__ half *)pooling2d_max3 + 768), 0, 1, 16, 48, 0);
  wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
  wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
  pipe_barrier(PIPE_ALL);
}

