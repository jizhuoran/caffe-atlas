#ifdef __CCE_KT_TEST__
#define __aicore__ 
#else
#define __aicore__ [aicore]
#endif

extern "C"  __global__ __aicore__ void conv_bw_input_op_64_64_64_8_8_3_3_1_1_1_1__kernel0(__gm__ half* __restrict__ filter, __gm__ half* __restrict__ dedy, __gm__ half* __restrict__ c_ddr) {
set_l1_3d_size(0);
set_padding(0);
__cbuf__   half* filter_local_L1 = (__cbuf__  half *)get_imm(0);
__cbuf__   half* dedy_local_L1_1 = (__cbuf__  half *)get_imm(73728);
__cc__   float* C_2 = (__cc__  float *)get_imm(0);
__ca__   half* im2col_fractal_4 = (__ca__  half *)get_imm(0);
__cb__   half* w_col_5 = (__cb__  half *)get_imm(0);
__ca__   half* im2col_fractal_6 = (__ca__  half *)get_imm(18432);
__cb__   half* w_col_7 = (__cb__  half *)get_imm(18432);
__ubuf__   half* c_ub_3 = (__ubuf__  half *)get_imm(0);
__cbuf__   half* dedy_local_L1_8 = (__cbuf__  half *)get_imm(81920);
__cc__   float* C_9 = (__cc__  float *)get_imm(16384);
__ubuf__   half* c_ub_10 = (__ubuf__  half *)get_imm(8192);
  set_fmatrix(0x101010100080008);
  set_padding((uint64_t)0ULL);
  copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1), ((__gm__ half *)filter), 0, 1, 2304, 0, 0, PAD_NONE);
  for (int32_t dx_batch_idx_outer_inner_db = 0; dx_batch_idx_outer_inner_db < 16; ++dx_batch_idx_outer_inner_db) {
    if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    }
    copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L1_1), ((__gm__ half *)dedy + ((((int32_t)block_idx) * 131072) + (dx_batch_idx_outer_inner_db * 8192))), 0, 1, 256, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_V, PIPE_M, EVENT_ID0);
    }
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t axis_k1_outer_db = 0; axis_k1_outer_db < 2; ++axis_k1_outer_db) {
      if ((axis_k1_outer_db + dx_batch_idx_outer_inner_db) != 0) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      for (int32_t lower = 0; lower < 4; ++lower) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)(((((int64_t)(axis_k1_outer_db * 2)) * (int64_t)9) - ((int64_t)(((uint64_t)((int64_t)(axis_k1_outer_db * 2))) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (int64_t)-1, ((((int64_t)lower) * (int64_t)2) - (int64_t)1), ((uint64_t)((int64_t)(axis_k1_outer_db * 2))), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
      }
      for (int32_t w_k1_idx = 0; w_k1_idx < 9; ++w_k1_idx) {
        load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx * 1024)), ((__cbuf__ half *)filter_local_L1 + (((axis_k1_outer_db * 512) + 8192) - (w_k1_idx * 1024))), 0, 4, 36, 0, 1);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (axis_k1_outer_db == 0));
      set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      if ((axis_k1_outer_db + dx_batch_idx_outer_inner_db) != 0) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
      for (int32_t lower1 = 0; lower1 < 4; ++lower1) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower1 * 2304)), ((__cbuf__ half *)dedy_local_L1_1), ((uint64_t)(((((int64_t)((axis_k1_outer_db * 2) + 1)) * (int64_t)9) - ((int64_t)(((uint64_t)((int64_t)((axis_k1_outer_db * 2) + 1))) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (int64_t)-1, ((((int64_t)lower1) * (int64_t)2) - (int64_t)1), ((uint64_t)((int64_t)((axis_k1_outer_db * 2) + 1))), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
      }
      for (int32_t w_k1_idx1 = 0; w_k1_idx1 < 9; ++w_k1_idx1) {
        load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx1 * 1024)), ((__cbuf__ half *)filter_local_L1 + (((axis_k1_outer_db * 512) + 8448) - (w_k1_idx1 * 1024))), 0, 4, 36, 0, 1);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      mad(((__cc__ float *)C_2), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
      set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
    }
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    }
    set_flag(PIPE_M, PIPE_V, EVENT_ID0);
    if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    }
    wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
    copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_3), ((__cc__ float *)C_2), 0, 1, 16, 0, 0, CRMODE_F32toF16_NONE);
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_V, PIPE_M, EVENT_ID0);
    }
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    for (int32_t dx_cin1_idx_inner = 0; dx_cin1_idx_inner < 4; ++dx_cin1_idx_inner) {
      copy_ubuf_to_gm(((__gm__ half *)c_ddr + (((((int32_t)block_idx) * 131072) + (dx_batch_idx_outer_inner_db * 8192)) + (dx_cin1_idx_inner * 1024))), ((__ubuf__ half *)c_ub_3 + (dx_cin1_idx_inner * 1024)), 0, 1, 64, 0, 0);
    }
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    }
    if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    }
    copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L1_8), ((__gm__ half *)dedy + (((((int32_t)block_idx) * 131072) + (dx_batch_idx_outer_inner_db * 8192)) + 4096)), 0, 1, 256, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_V, PIPE_M, EVENT_ID1);
    }
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t axis_k1_outer_db1 = 0; axis_k1_outer_db1 < 2; ++axis_k1_outer_db1) {
      wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      for (int32_t lower2 = 0; lower2 < 4; ++lower2) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4 + (lower2 * 2304)), ((__cbuf__ half *)dedy_local_L1_8), ((uint64_t)(((((int64_t)(axis_k1_outer_db1 * 2)) * (int64_t)9) - ((int64_t)(((uint64_t)((int64_t)(axis_k1_outer_db1 * 2))) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (int64_t)-1, ((((int64_t)lower2) * (int64_t)2) - (int64_t)1), ((uint64_t)((int64_t)(axis_k1_outer_db1 * 2))), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
      }
      for (int32_t w_k1_idx2 = 0; w_k1_idx2 < 9; ++w_k1_idx2) {
        load_cbuf_to_cb(((__cb__ half *)w_col_5 + (w_k1_idx2 * 1024)), ((__cbuf__ half *)filter_local_L1 + (((axis_k1_outer_db1 * 512) + 8192) - (w_k1_idx2 * 1024))), 0, 4, 36, 0, 1);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      mad(((__cc__ float *)C_9), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col_5), 64, 144, 64, (axis_k1_outer_db1 == 0));
      if ((axis_k1_outer_db1 + dx_batch_idx_outer_inner_db) != 16) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      for (int32_t lower3 = 0; lower3 < 4; ++lower3) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_6 + (lower3 * 2304)), ((__cbuf__ half *)dedy_local_L1_8), ((uint64_t)(((((int64_t)((axis_k1_outer_db1 * 2) + 1)) * (int64_t)9) - ((int64_t)(((uint64_t)((int64_t)((axis_k1_outer_db1 * 2) + 1))) * (uint64_t)9ULL))) % (int64_t)3)), (uint64_t)0ULL, (int64_t)-1, ((((int64_t)lower3) * (int64_t)2) - (int64_t)1), ((uint64_t)((int64_t)((axis_k1_outer_db1 * 2) + 1))), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)3ULL, (uint64_t)3ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)9ULL, CSIZE0);
      }
      for (int32_t w_k1_idx3 = 0; w_k1_idx3 < 9; ++w_k1_idx3) {
        load_cbuf_to_cb(((__cb__ half *)w_col_7 + (w_k1_idx3 * 1024)), ((__cbuf__ half *)filter_local_L1 + (((axis_k1_outer_db1 * 512) + 8448) - (w_k1_idx3 * 1024))), 0, 4, 36, 0, 1);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      mad(((__cc__ float *)C_9), ((__ca__ half *)im2col_fractal_6), ((__cb__ half *)w_col_7), 64, 144, 64, (int8_t)0ULL);
      if ((axis_k1_outer_db1 + dx_batch_idx_outer_inner_db) != 16) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
    }
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    }
    set_flag(PIPE_M, PIPE_V, EVENT_ID0);
    if (0 < dx_batch_idx_outer_inner_db) {
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    }
    wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
    copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub_10), ((__cc__ float *)C_9), 0, 1, 16, 0, 0, CRMODE_F32toF16_NONE);
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_V, PIPE_M, EVENT_ID1);
    }
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    for (int32_t dx_cin1_idx_inner1 = 0; dx_cin1_idx_inner1 < 4; ++dx_cin1_idx_inner1) {
      copy_ubuf_to_gm(((__gm__ half *)c_ddr + ((((((int32_t)block_idx) * 131072) + (dx_batch_idx_outer_inner_db * 8192)) + (dx_cin1_idx_inner1 * 1024)) + 4096)), ((__ubuf__ half *)c_ub_10 + (dx_cin1_idx_inner1 * 1024)), 0, 1, 64, 0, 0);
    }
    if (dx_batch_idx_outer_inner_db < 15) {
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    }
  }
  pipe_barrier(PIPE_ALL);
}

