#ifdef __CCE_KT_TEST__
#define __aicore__ 
#else
#define __aicore__ [aicore]
#endif

extern "C"  __global__ __aicore__ void conv_bw_input_op_64_20_50_12_12_5_5_0_0_1_1__kernel0(__gm__ half* __restrict__ filter, __gm__ half* __restrict__ dedy, __gm__ half* __restrict__ c_ddr) {
set_l1_3d_size(0);
set_padding(0);
__cbuf__   half* filter_local_L1 = (__cbuf__  half *)get_imm(0);
__cb__   half* w_col = (__cb__  half *)get_imm(0);
__cbuf__   half* dedy_local_L1 = (__cbuf__  half *)get_imm(51200);
__cc__   float* C = (__cc__  float *)get_imm(0);
__ca__   half* im2col_fractal_1 = (__ca__  half *)get_imm(0);
__ca__   half* im2col_fractal_2 = (__ca__  half *)get_imm(20480);
__ubuf__   half* c_ub = (__ubuf__  half *)get_imm(0);
__cbuf__   half* dedy_local_L11 = (__cbuf__  half *)get_imm(59392);
__cc__   float* C1 = (__cc__  float *)get_imm(8192);
__ca__   half* im2col_fractal_3 = (__ca__  half *)get_imm(40960);
__ca__   half* im2col_fractal_4 = (__ca__  half *)get_imm(43520);
__ubuf__   half* c_ub1 = (__ubuf__  half *)get_imm(4096);
  set_padding((uint64_t)0ULL);
  copy_gm_to_cbuf(((__cbuf__ half *)filter_local_L1), ((__gm__ half *)filter + ((((int32_t)block_idx) & 1) * 25600)), 0, 1, 1600, 0, 0, PAD_NONE);
  set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
  for (int32_t w_k1_idx = 0; w_k1_idx < 100; ++w_k1_idx) {
    load_cbuf_to_cb(((__cb__ half *)w_col + (w_k1_idx * 256)), ((__cbuf__ half *)filter_local_L1 + ((((w_k1_idx / 25) * 256) + 24576) - ((w_k1_idx % 25) * 1024))), 0, 1, 0, 0, 1);
  }
  for (int32_t dx_batch_idx_outer_inner = 0; dx_batch_idx_outer_inner < 32; ++dx_batch_idx_outer_inner) {
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    }
    copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L1), ((__gm__ half *)dedy + (((((int32_t)block_idx) >> 1) * 131072) + (dx_batch_idx_outer_inner * 4096))), 0, 1, 256, 0, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        set_fmatrix(0x404040400080008);
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_V, PIPE_M, EVENT_ID0);
    }
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t axis_k1_outer_db = 0; axis_k1_outer_db < 10; ++axis_k1_outer_db) {
      if (0 < axis_k1_outer_db) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      for (int32_t lower = 0; lower < 5; ++lower) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_1 + (lower * 256)), ((__cbuf__ half *)dedy_local_L1), ((uint64_t)((((((int64_t)(axis_k1_outer_db * 2)) * (int64_t)5) + ((int64_t)lower)) - ((int64_t)(((uint64_t)(((((int64_t)(axis_k1_outer_db * 2)) * (int64_t)5) + ((int64_t)lower)) / (int64_t)25)) * (uint64_t)25ULL))) % (int64_t)5)), ((uint64_t)((((((int64_t)(axis_k1_outer_db * 2)) * (int64_t)5) + ((int64_t)lower)) % (int64_t)25) / (int64_t)5)), (int64_t)-4, (int64_t)-4, ((uint64_t)(((((int64_t)(axis_k1_outer_db * 2)) * (int64_t)5) + ((int64_t)lower)) / (int64_t)25)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)8ULL, CSIZE0);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      pipe_barrier(PIPE_M);
      mad(((__cc__ float *)C), ((__ca__ half *)im2col_fractal_1), ((__cb__ half *)w_col + (axis_k1_outer_db * 2560)), 128, 80, 16, (axis_k1_outer_db == 0));
      if (axis_k1_outer_db < 9) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      if (0 < axis_k1_outer_db) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
      for (int32_t lower1 = 0; lower1 < 5; ++lower1) {
        img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_2 + (lower1 * 256)), ((__cbuf__ half *)dedy_local_L1), ((uint64_t)((((((int64_t)((axis_k1_outer_db * 2) + 1)) * (int64_t)5) + ((int64_t)lower1)) - ((int64_t)(((uint64_t)(((((int64_t)((axis_k1_outer_db * 2) + 1)) * (int64_t)5) + ((int64_t)lower1)) / (int64_t)25)) * (uint64_t)25ULL))) % (int64_t)5)), ((uint64_t)((((((int64_t)((axis_k1_outer_db * 2) + 1)) * (int64_t)5) + ((int64_t)lower1)) % (int64_t)25) / (int64_t)5)), (int64_t)-4, (int64_t)-4, ((uint64_t)(((((int64_t)((axis_k1_outer_db * 2) + 1)) * (int64_t)5) + ((int64_t)lower1)) / (int64_t)25)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)8ULL, CSIZE0);
      }
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      pipe_barrier(PIPE_M);
      mad(((__cc__ float *)C), ((__ca__ half *)im2col_fractal_2), ((__cb__ half *)w_col + ((axis_k1_outer_db * 2560) + 1280)), 128, 80, 16, (int8_t)0ULL);
      if (axis_k1_outer_db < 9) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
    }
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID0);
    }
    set_flag(PIPE_M, PIPE_V, EVENT_ID0);
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    }
    wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
    copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub), ((__cc__ float *)C), 0, 1, 8, 0, 0, CRMODE_F32toF16_NONE);
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_V, PIPE_M, EVENT_ID0);
    }
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)c_ddr + ((((((int32_t)block_idx) >> 1) * 147456) + (dx_batch_idx_outer_inner * 4608)) + ((((int32_t)block_idx) & 1) * 2304))), ((__ubuf__ half *)c_ub), 0, 1, 128, 0, 0);
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID0);
    }
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    }
    copy_gm_to_cbuf(((__cbuf__ half *)dedy_local_L11), ((__gm__ half *)dedy + ((((((int32_t)block_idx) >> 1) * 131072) + (dx_batch_idx_outer_inner * 4096)) + 768)), 0, 4, 16, 48, 0, PAD_NONE);
    set_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
        set_fmatrix(0x400040400020008);
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_V, PIPE_M, EVENT_ID1);
    }
    wait_flag(PIPE_MTE2, PIPE_MTE1, EVENT_ID0);
    for (int32_t axis_k1_outer_db1 = 0; axis_k1_outer_db1 < 10; ++axis_k1_outer_db1) {
      if (0 < axis_k1_outer_db1) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_3), ((__cbuf__ half *)dedy_local_L11), ((uint64_t)(((((int64_t)(axis_k1_outer_db1 * 2)) * (int64_t)5) - ((int64_t)(((uint64_t)(((int64_t)(axis_k1_outer_db1 * 2)) / (int64_t)5)) * (uint64_t)25ULL))) % (int64_t)5)), ((uint64_t)(((int64_t)(axis_k1_outer_db1 * 2)) % (int64_t)5)), (int64_t)4, (int64_t)0, ((uint64_t)(((int64_t)(axis_k1_outer_db1 * 2)) / (int64_t)5)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)5ULL, CSIZE0);
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      pipe_barrier(PIPE_M);
      mad(((__cc__ float *)C1), ((__ca__ half *)im2col_fractal_3), ((__cb__ half *)w_col + (axis_k1_outer_db1 * 2560)), 16, 80, 16, (axis_k1_outer_db1 == 0));
      if (axis_k1_outer_db1 < 9) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID0);
      }
      if (0 < axis_k1_outer_db1) {
        wait_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
      img2col_cbuf_to_ca(((__ca__ half *)im2col_fractal_4), ((__cbuf__ half *)dedy_local_L11), ((uint64_t)(((((int64_t)((axis_k1_outer_db1 * 2) + 1)) * (int64_t)5) - ((int64_t)(((uint64_t)(((int64_t)((axis_k1_outer_db1 * 2) + 1)) / (int64_t)5)) * (uint64_t)25ULL))) % (int64_t)5)), ((uint64_t)(((int64_t)((axis_k1_outer_db1 * 2) + 1)) % (int64_t)5)), (int64_t)4, (int64_t)0, ((uint64_t)(((int64_t)((axis_k1_outer_db1 * 2) + 1)) / (int64_t)5)), (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)5ULL, (uint64_t)5ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)1ULL, (uint64_t)0ULL, (uint64_t)5ULL, CSIZE0);
      set_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      wait_flag(PIPE_MTE1, PIPE_M, EVENT_ID0);
      pipe_barrier(PIPE_M);
      mad(((__cc__ float *)C1), ((__ca__ half *)im2col_fractal_4), ((__cb__ half *)w_col + ((axis_k1_outer_db1 * 2560) + 1280)), 16, 80, 16, (int8_t)0ULL);
      if (axis_k1_outer_db1 < 9) {
        set_flag(PIPE_M, PIPE_MTE1, EVENT_ID1);
      }
    }
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_MTE1, PIPE_MTE2, EVENT_ID1);
    }
    set_flag(PIPE_M, PIPE_V, EVENT_ID0);
    if (0 < dx_batch_idx_outer_inner) {
      wait_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    }
    wait_flag(PIPE_M, PIPE_V, EVENT_ID0);
    copy_matrix_cc_to_ubuf(((__ubuf__ half *)c_ub1), ((__cc__ float *)C1), 0, 1, 1, 0, 0, CRMODE_F32toF16_NONE);
    set_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_V, PIPE_M, EVENT_ID1);
    }
    wait_flag(PIPE_V, PIPE_MTE3, EVENT_ID0);
    copy_ubuf_to_gm(((__gm__ half *)c_ddr + (((((((int32_t)block_idx) >> 1) * 147456) + (dx_batch_idx_outer_inner * 4608)) + ((((int32_t)block_idx) & 1) * 2304)) + 2048)), ((__ubuf__ half *)c_ub1), 0, 1, 16, 0, 0);
    if (dx_batch_idx_outer_inner < 31) {
      set_flag(PIPE_MTE3, PIPE_V, EVENT_ID1);
    }
  }
  pipe_barrier(PIPE_ALL);
}

